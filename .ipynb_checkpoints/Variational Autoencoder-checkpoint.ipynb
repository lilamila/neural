{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoders\n",
    "\n",
    "(notes from FFlabs' [blog](http://blog.fastforwardlabs.com/))\n",
    "A development in unsupervised machine learning that combines probabilistic Bayesian inference with deep learning\n",
    "\n",
    "Traditional autoencoders models (usually multilayer ANNs) designed to output reconstruction of input.\n",
    "\n",
    "Representation learning --> the model learns own definition of 'meaningful' representation based only on data.\n",
    "\n",
    "Many deep learning systems in production today rely on expensive-to-obtain labeled data.\n",
    "\n",
    "Though trained holistically, autoencoders often built for part instead of whole.\n",
    "\n",
    "VAEs incorp regularization by explicitely learning joint distribution over data and a set of latent variables that is most compatibe with observed datapoints and some designated prior distribution over latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
